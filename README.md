# WebFetch - Comprehensive Web Content Fetching Library

A powerful, production-ready web fetching library with advanced features including authentication, caching, batch operations, file handling, and extensive HTTP support. Built with modern Python 3.11+ features and AIOHTTP for efficient asynchronous operations.

> ğŸ“š **[Complete Documentation](https://astroair.github.io/web-fetch/)** | ğŸš€ **[Quick Start Guide](docs/getting-started/quick-start.md)** | ğŸ“– **[API Reference](docs/api/core.md)**

## âœ¨ Key Features

- **ğŸš€ Async/Await**: Modern Python async patterns with AIOHTTP
- **ğŸ“¦ Batch Operations**: Concurrent fetching with intelligent scheduling
- **ğŸ”„ Streaming**: Memory-efficient downloads with progress tracking
- **ğŸ” Authentication**: OAuth, API keys, JWT, and more
- **ğŸ•·ï¸ Web Crawling**: Integrated crawler APIs (Firecrawl, Tavily, Spider)
- **ğŸ’¾ Caching**: Multiple backends with TTL and compression
- **ğŸ¨ Rich CLI**: Beautiful command-line interface with progress bars
- **ğŸ”§ MCP Integration**: Model Context Protocol server support
- **ğŸ“Š Content Parsing**: JSON, HTML, PDF, images, RSS feeds
- **âš¡ High Performance**: Connection pooling, rate limiting, circuit breakers

## ğŸ“¦ Installation

```bash
# Basic installation
pip install web-fetch

# With all features
pip install "web-fetch[all-crawlers,mcp,caching]"

# From source
git clone https://github.com/AstroAir/web-fetch.git
cd web-fetch
pip install -e ".[all]"
```

> ğŸ“‹ **[Complete Installation Guide](docs/getting-started/installation.md)** - Detailed installation instructions and troubleshooting

## ğŸ”§ Quick Start

### Simple Usage

```python
import asyncio
from web_fetch import fetch_url, ContentType

async def main():
    # Fetch JSON data
    result = await fetch_url("https://httpbin.org/json", ContentType.JSON)
    if result.is_success:
        print(f"Status: {result.status_code}")
        print(f"Content: {result.content}")

asyncio.run(main())
```

### Batch Fetching

```python
from web_fetch import fetch_urls, ContentType

async def main():
    urls = ["https://httpbin.org/get", "https://httpbin.org/json"]
    result = await fetch_urls(urls, ContentType.JSON)
    print(f"Success rate: {result.success_rate:.1f}%")

asyncio.run(main())
```

### File Downloads

```python
from web_fetch import download_file
from pathlib import Path

async def main():
    result = await download_file(
        "https://httpbin.org/bytes/1048576",
        Path("downloads/file.bin")
    )
    print(f"Downloaded {result.bytes_downloaded:,} bytes")

asyncio.run(main())
```

> ğŸš€ **[More Examples](docs/getting-started/basic-examples.md)** - Comprehensive usage examples and patterns

## ğŸ–¥ï¸ Command Line Interface

WebFetch includes a powerful CLI with enhanced formatting:

```bash
# Simple URL fetch
web-fetch https://httpbin.org/json

# Batch fetch from file
web-fetch --batch urls.txt --concurrent 5

# POST request with data
web-fetch --method POST --data '{"key":"value"}' https://httpbin.org/post

# Streaming download with progress
web-fetch --stream --progress https://example.com/file.zip -o file.zip
```

### Enhanced Features

- ğŸ¨ **Colored Output** - Success (green), errors (red), warnings (yellow)
- ğŸ“Š **Progress Bars** - Visual progress for downloads and batch operations
- ğŸ“‹ **Formatted Tables** - Beautiful structured data display
- ğŸ”„ **Graceful Fallbacks** - Works with or without rich library

```bash
# Install for enhanced formatting
pip install rich>=13.0.0
```

> ğŸ–¥ï¸ **[Complete CLI Guide](docs/cli/overview.md)** - All CLI options and examples

## ğŸ“š Documentation

### Complete Documentation

- ğŸ“– **[API Reference](docs/api/core.md)** - Complete API documentation
- âš™ï¸ **[Configuration Guide](docs/user-guide/configuration.md)** - Setup and configuration
- ğŸš€ **[Getting Started](docs/getting-started/quick-start.md)** - Quick start guide
- ğŸ’¡ **[Examples](docs/examples/basic.md)** - Usage examples and patterns
- ğŸ–¥ï¸ **[CLI Tools](docs/cli/overview.md)** - Command-line interface
- ğŸ”§ **[Development](docs/development/contributing.md)** - Contributing and development

### Quick API Overview

```python
# Core classes
from web_fetch import WebFetcher, FetchConfig, FetchRequest, ContentType

# Configuration
config = FetchConfig(
    total_timeout=30.0,
    max_concurrent_requests=10,
    max_retries=3
)

# Request
request = FetchRequest(
    url="https://api.example.com",
    method="POST",
    headers={"Authorization": "Bearer token"},
    data={"key": "value"},
    content_type=ContentType.JSON
)

# Fetch
async with WebFetcher(config) as fetcher:
    result = await fetcher.fetch_single(request)
    if result.is_success:
        print(result.content)
```

### Content Types & Utilities

- `ContentType.TEXT` - UTF-8 text
- `ContentType.JSON` - JSON objects
- `ContentType.HTML` - Parsed HTML with structured data
- `ContentType.RAW` - Raw bytes

```python
# URL utilities
from web_fetch import is_valid_url, normalize_url, fetch_with_cache

# Validation and normalization
if is_valid_url(url):
    normalized = normalize_url(url)

# Caching
result = await fetch_with_cache(url)  # Automatic caching
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=web_fetch

# Run specific tests
pytest tests/test_fetcher.py -v
```

> ğŸ§ª **[Testing Guide](docs/development/testing.md)** - Complete testing documentation

## ğŸ“ Project Structure

```text
web-fetch/
â”œâ”€â”€ web_fetch/           # Main package
â”‚   â”œâ”€â”€ core/           # Core HTTP implementation
â”‚   â”œâ”€â”€ ftp/            # FTP functionality
â”‚   â”œâ”€â”€ crawlers/       # Crawler integrations
â”‚   â”œâ”€â”€ parsers/        # Content parsers
â”‚   â”œâ”€â”€ utils/          # Utilities and helpers
â”‚   â””â”€â”€ cli/            # Command-line interface
â”œâ”€â”€ tests/              # Comprehensive test suite
â”œâ”€â”€ docs/               # Documentation (MkDocs)
â”œâ”€â”€ examples/           # Usage examples
â””â”€â”€ scripts/            # Development scripts
```

> ğŸ—ï¸ **[Architecture Guide](docs/development/architecture.md)** - Detailed architecture overview

## ğŸš€ Performance & Best Practices

- **Use batch fetching** for multiple URLs to leverage concurrency
- **Configure appropriate timeouts** for your use case
- **Use connection pooling** by reusing WebFetcher instances
- **Set response size limits** to prevent memory issues
- **Choose appropriate content types** to avoid unnecessary parsing

> âš¡ **[Performance Guide](docs/advanced/performance.md)** - Detailed optimization strategies

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](docs/development/contributing.md) for details.

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [AIOHTTP](https://docs.aiohttp.org/) for async HTTP handling
- Uses [Pydantic](https://pydantic-docs.helpmanual.io/) for data validation
- HTML parsing powered by [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)
- Inspired by modern Python async patterns and best practices

---

**[ğŸ“š Full Documentation](https://astroair.github.io/web-fetch/)** | **[ğŸ› Report Issues](https://github.com/AstroAir/web-fetch/issues)** | **[ğŸ’¬ Discussions](https://github.com/AstroAir/web-fetch/discussions)**
